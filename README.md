# Mathematics-for-AI

Topics Covered in this topic:
1. Vectors, Definition,
2. Scalars, Addition, Scalar Multiplication
3. Inner Product (Dot Product), Vector Projection
4. Cosine Similarity, Orthogonal Vectors
5. Normal And Orthonormal Vectors
6. Vector Norm, Vector Space
7. Linear Combination, Linear Span
8. Linear Independence, Basis Vectors
9. Linear Independence
10. Basis and Rank
11. Linear Mappings
12. Affine Spaces
13. Matrices Definition, Addition, Transpose
14. Scalar Multiplication, Matrix Multiplication, Matrix Multiplication Properties
15. Hadamard Product, Functions, Linear Transformation, Determinant, Identity Matrix,
16. Invertible
17. Matrix and Inverse, Rank, Trace
18. Popular Type of Matrices- Symmetric, Diagonal, Orthogonal, Orthonormal
19. Positive Definite Matrix
20. Matrix Phylogeny
21. Matrix Approximation
22. Eigen Values & Eigenvectors, Concept, Intuition, Significance
23. How To Find Principle Component Analysis
24. Concept, Properties, Applications
25. Singular Value Decomposition
26. Functions, Scalar Derivative, Definition, Intuition
27. Common Rules Of Differentiation, Chain Rule
28. Partial Derivatives, Gradient
29. Concept, Intuition, Properties
30. Directional Derivative
31. Gradients of Vector Valued Functions
32. Gradient of Matrices
33. Useful Identities for Computing Gradients
34. Back propagation and Automatic Differentiation
35. Linearization and Multivariate Taylor Series
36. Optimization Using Gradient Descent
37. Constrained Optimization and Lagrange Multipliers
38. Convex Optimization
39. Vector And Matrix Calculus
40. How To Find Derivative Of Scalar-Valued
41. Vector-Valued Function With Respect To Scalar, Vector , Four Combinations- Jacobian
42. Gradient Algorithms, Local/Global Maxima and Minima
43. Saddle Point, Convex Functions
44. Gradient Descent Algorithms- Batch, Mini-Batch, Stochastic
45. Performance Comparison
